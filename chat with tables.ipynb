{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import uuid\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.schema.document import Document\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from transformers import pipeline\n",
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = input(\"Enter the path to the file:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pdf_elements=partition_pdf(\n",
    "    filename=filepath,\n",
    "    strategy=\"hi_res\",\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters= 3000,\n",
    "    new_after_n_chars= 2500,\n",
    "    combine_text_under_n_chars= 1500,\n",
    "\t infer_table_structure= True ,\n",
    "    extract_images_in_pdf= False,                   \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=[]\n",
    "for element in raw_pdf_elements:\n",
    "  if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "            table.append(str(element))\n",
    "\n",
    "text=[]\n",
    "for element in raw_pdf_elements:\n",
    "  if \"unstructured.documents.elements.NarrativeText\" in str(type(element)):\n",
    "            text.append(str(element))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"You are an AI assistant tasked with generating summaries of tables for retrieval.\\\n",
    "    These summaries will be embedded and will be used to retrieve the table elements at a later time.\\\n",
    "    Give a concise summary of the table that is well optimized for retrieval.\\\n",
    "    Table:{element} \"\"\"\n",
    "\n",
    "prompt= ChatPromptTemplate.from_template(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=pipeline(task='Text Generation', model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_chain={\"element\": lambda x:x} | prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_content = [elements.text for elements in table]\n",
    "table_summaries = summarize_chain.batch(table_content, {'max_concurrency': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_content = [elements.text for elements in text]\n",
    "text_summaries = summarize_chain.batch(text_content, {'max_concurrency': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = \"BAAI/bge-large-en-v1.5\")\n",
    "vector_store = Chroma(collection_name=\"Summaries\",\n",
    "                      embedding_function=embeddings)\n",
    "\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\" \n",
    "\n",
    "retriever = MultiVectorRetriever(vector_store=vector_store, \n",
    "                                 doc_store=store, \n",
    "                                 id_key=id_key)\n",
    "\n",
    "text_ids=[str(uuid.uuid4()) for _ in text_content]\n",
    "summary_text = [Document(page_content = content, metadata={id_key: text_ids[i]}) for i, content in enumerate(text_summaries)]\n",
    "retriever.vectorstore.add_documents(summary_text)\n",
    "retriever.docstore.mset(list(zip(text_ids, text_content)))\n",
    "\n",
    "table_ids=[str(uuid.uuid4()) for _ in table_content]\n",
    "summary_table = [Document(page_content = content, metadata={id_key: table_ids[i]}) for i, content in enumerate(table_summaries)]\n",
    "retriever.vectorstore.add_documents(summary_table)\n",
    "retriever.docstore.mset(list(zip(table_ids, table_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based on the following context. Also remember the history of previous answers, so if you are asked about anything regarding the previous chat, you can use that information to answer the question as well.\n",
    "Context: {context}\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "chain = (\n",
    "{'context': retriever, 'question': RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "        query = input(\"\\n\\nAsk your question (Type 'exit' to exit...): \\n\")\n",
    "        if query.lower() == \"exit\" :\n",
    "            print(\"\\n-------------------------\\nThank you for using the service!!\")\n",
    "            exit()\n",
    "\n",
    "        response = chain.invoke(query)\n",
    "        print(f\"\\n\\nResponse: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
